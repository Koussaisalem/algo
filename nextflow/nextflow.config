/*
 * Nextflow Configuration File
 * Quantum Materials Discovery Platform
 */

// Manifest
manifest {
    name            = 'Quantum Materials Discovery Pipeline'
    author          = 'Koussai Salem'
    homePage        = 'https://github.com/Koussaisalem/algo'
    description     = 'End-to-end pipeline for quantum materials discovery using manifold diffusion'
    mainScript      = 'main.nf'
    nextflowVersion = '>=21.04.0'
    version         = '1.0.0'
}

// Default parameters
params {
    // Input/Output
    raw_dataset = "${projectDir}/projects/phononic-discovery/framework/data/qm9/qm9_micro_raw.pt"
    output_dir = "${projectDir}/results/pipeline_output"
    
    // Training parameters
    num_epochs_surrogate = 50
    num_epochs_score = 100
    num_samples = 100
    
    // Hardware
    max_cpus = 8
    max_memory = '32.GB'
    max_time = '24.h'
    
    // Help
    help = false
}

// Process configuration
process {
    // Default resources
    cpus = 4
    memory = '16 GB'
    time = '4h'
    
    // Error handling
    errorStrategy = 'retry'
    maxRetries = 2
    
    // Process-specific configurations
    withName: data_preparation {
        cpus = 2
        memory = '8 GB'
        time = '30m'
    }
    
    withName: xtb_enrichment {
        cpus = 4
        memory = '16 GB'
        time = '2h'
    }
    
    withName: surrogate_training {
        cpus = 8
        memory = '32 GB'
        time = '8h'
    }
    
    withName: score_training {
        cpus = 8
        memory = '32 GB'
        time = '12h'
    }
    
    withName: generative_sampling {
        cpus = 4
        memory = '16 GB'
        time = '1h'
    }
    
    withName: dft_validation {
        cpus = 8
        memory = '32 GB'
        time = '24h'
    }
    
    withName: analysis_visualization {
        cpus = 2
        memory = '8 GB'
        time = '30m'
    }
    
    withName: advanced_benchmarking {
        cpus = 4
        memory = '16 GB'
        time = '2h'
    }
}

// Execution profiles
profiles {
    standard {
        process.executor = 'local'
    }
    
    docker {
        docker.enabled = true
        docker.runOptions = '--gpus all'
        process.container = 'pytorch/pytorch:2.1.0-cuda11.8-cudnn8-runtime'
    }
    
    conda {
        conda.enabled = true
        process.conda = "${projectDir}/environment.yml"
    }
    
    cluster {
        process.executor = 'slurm'
        process.queue = 'gpu'
        process.clusterOptions = '--gres=gpu:1'
    }
    
    test {
        params.num_epochs_surrogate = 2
        params.num_epochs_score = 2
        params.num_samples = 10
        process.cpus = 2
        process.memory = '8 GB'
        process.time = '30m'
    }
}

// Report and trace
timeline {
    enabled = true
    file = "${params.output_dir}/timeline.html"
}

report {
    enabled = true
    file = "${params.output_dir}/report.html"
}

trace {
    enabled = true
    file = "${params.output_dir}/trace.txt"
}

dag {
    enabled = true
    file = "${params.output_dir}/dag.svg"
}

// Logging
workDir = "${params.output_dir}/work"
